{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "ce4051c1-4f85-4950-b441-53bca85cc277",
          "showTitle": false,
          "title": ""
        },
        "id": "c9z6z05aaHIW"
      },
      "source": [
        "# Logistic regression on Criteo dataset without Spark MLlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EYWH2dNiBqw"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!curl -O https://dlcdn.apache.org/spark/spark-3.2.4/spark-3.2.4-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.4-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clY_XThgiEQO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.4-bin-hadoop3.2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jp4U9E35iG_e"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "conf = SparkConf().set('spark.ui.port', '4050')\n",
        "sc = SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.master('local[*]').getOrCreate()\n",
        "ss = spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "a03b37ed-b018-4656-a023-ee19ac83aee4",
          "showTitle": false,
          "title": ""
        },
        "id": "-5-hWwHXaHIb"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import types as st\n",
        "from pyspark.sql import functions as sf\n",
        "from pyspark.sql import Row, DataFrame\n",
        "from pyspark import RDD\n",
        "from pyspark import StorageLevel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "f81cca61-e319-4be1-ac1e-5af57d12b0c0",
          "showTitle": false,
          "title": ""
        },
        "id": "xlR2RatxaHIe"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "96c19685-5bae-4d9b-8e26-f894cfe95150",
          "showTitle": false,
          "title": ""
        },
        "id": "gwbGfL69aHIg"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import urllib\n",
        "import matplotlib.pyplot as plot\n",
        "from typing import Tuple, Dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UmOA5tmjTlG"
      },
      "outputs": [],
      "source": [
        "ss=spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "d8fbc9cb-8911-4b90-8c04-6ca56a92679e",
          "showTitle": false,
          "title": ""
        },
        "id": "xxE7YvATaHIm"
      },
      "outputs": [],
      "source": [
        "integer_features = [f\"int_feat_{i}\" for i in range(1, 14)]\n",
        "categorical_features = [f\"cat_feat_{i}\" for i in range(1, 27)]\n",
        "\n",
        "fields = []\n",
        "\n",
        "fields.append(\n",
        "    st.StructField(\"label\", st.IntegerType(), nullable=False)\n",
        ")\n",
        "\n",
        "for int_feat in integer_features:\n",
        "    fields.append(st.StructField(int_feat, st.IntegerType(), nullable=True))\n",
        "    \n",
        "for cat_feat in categorical_features:\n",
        "    fields.append(st.StructField(cat_feat, st.StringType(), nullable=True))\n",
        "\n",
        "schema = st.StructType(fields)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "630d0e64-2505-4a72-b632-306f548287df",
          "showTitle": false,
          "title": ""
        },
        "id": "HZrfZzGCaHIn"
      },
      "outputs": [],
      "source": [
        "from urllib import request\n",
        "toy_dataset_url = 'https://www.dropbox.com/s/hn2pt29gbne9c99/criteo_toy_dataset-part2.txt?dl=1'\n",
        "request.urlretrieve(toy_dataset_url, \"train.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "debbde52-486f-4e65-9a38-7171b7db4d3a",
          "showTitle": false,
          "title": ""
        },
        "id": "DTVqzOC0aHIp"
      },
      "outputs": [],
      "source": [
        "full_df = ss.read.csv(\n",
        "    path=\"train.txt\",\n",
        "    sep=\"\\t\",\n",
        "    header=None,\n",
        "    schema=schema\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "439c9371-54d2-4824-8247-f04eeee58cb3",
          "showTitle": false,
          "title": ""
        },
        "id": "ofqmGJB3aHIr"
      },
      "outputs": [],
      "source": [
        "full_df.agg(\n",
        "    sf.count('*').alias('num_examples'),\n",
        "    sf.sum('label').alias('num_positives'),\n",
        "    sf.sum(sf.expr('label == 0').cast('int')).alias('num_negatives'),\n",
        "    sf.mean('label').alias('avg_label')\n",
        ").toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "3d6a0c68-ecac-4483-850d-26196a01976b",
          "showTitle": false,
          "title": ""
        },
        "id": "MHOxevw7aHIt"
      },
      "source": [
        "## Convert to vector with one hot encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "fe55e0e4-5f28-482d-921c-149c9599a536",
          "showTitle": false,
          "title": ""
        },
        "id": "Mfd6A1EIaHIu"
      },
      "source": [
        "### Select subset of features based on number of modalities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "b0c58f2c-128e-49d4-aafe-2631208d9d6c",
          "showTitle": false,
          "title": ""
        },
        "id": "LySKI564aHIv"
      },
      "outputs": [],
      "source": [
        "threshold = 100\n",
        "num_modalities = {} \n",
        "for cat_feat in categorical_features:\n",
        "    num_modalities[cat_feat] = full_df \\\n",
        "        .filter(sf.col(cat_feat).isNotNull()) \\\n",
        "        .groupby(cat_feat) \\\n",
        "        .count() \\\n",
        "        .filter(sf.col('count') > sf.lit(threshold)) \\\n",
        "        .count()\n",
        "num_modalities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "cbddee6f-8e02-40ea-b853-47e8e683e7d1",
          "showTitle": false,
          "title": ""
        },
        "id": "neBKCKEaaHI2"
      },
      "outputs": [],
      "source": [
        "low_card_cat_feat = [cat_feat for cat_feat, num_modalities in num_modalities.items() if num_modalities < 50]\n",
        "low_card_cat_feat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "2fbc43da-ced9-4229-ad84-bf3675fc197b",
          "showTitle": false,
          "title": ""
        },
        "id": "3-ma-OrYaHI3"
      },
      "source": [
        "### Build map for one hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "b445ce24-d832-4d74-a4f3-a98fe1ff4447",
          "showTitle": false,
          "title": ""
        },
        "id": "I5nCmSyvaHI4"
      },
      "outputs": [],
      "source": [
        "modalities = {}\n",
        "for cat_feat in low_card_cat_feat:\n",
        "    rows = full_df\\\n",
        "        .filter(sf.col(cat_feat).isNotNull())\\\n",
        "        .groupby(cat_feat)\\\n",
        "        .count()\\\n",
        "        .filter(sf.col('count') > sf.lit(threshold))\\\n",
        "        .select(cat_feat)\\\n",
        "        .collect()\n",
        "    modalities[cat_feat] = [row[cat_feat] for row in rows]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "6302f112-3515-42be-b52e-4914ef150da2",
          "showTitle": false,
          "title": ""
        },
        "id": "a2oOPjN-aHI5"
      },
      "outputs": [],
      "source": [
        "one_hot_encoder = {cat_feat:{} for cat_feat in low_card_cat_feat}\n",
        "index = 0\n",
        "for cat_feat in low_card_cat_feat:\n",
        "    for value in modalities[cat_feat]:\n",
        "        one_hot_encoder[cat_feat][value] = index\n",
        "        index += 1\n",
        "    one_hot_encoder[cat_feat][None] = index\n",
        "    index += 1\n",
        "dimension = index + 1 # dimension is nb_of_modalities + 1 for the intercept\n",
        "dimension"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "622b2057-f9cc-4f53-9e8a-fd51c85bdacd",
          "showTitle": false,
          "title": ""
        },
        "id": "Tb3V55fOaHI7"
      },
      "source": [
        "### Sparse methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "0d50e434-4a41-4fd2-862c-d48ebcab018d",
          "showTitle": false,
          "title": ""
        },
        "id": "Ko7otBwfaHI7"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "def dot_product(x: Dict[int,float], y: Dict[int,float]):\n",
        "  return functools.reduce(lambda a,b : a+b, [x[k]*y[k] for k in x.keys() & y.keys()])\n",
        "\n",
        "def product(x: Dict[int,float], coeff: float):\n",
        "  return {k:coeff*x[k] for k in x.keys()}\n",
        "\n",
        "epsilon = 1e-12\n",
        "def sum(a: Dict[int,float], b : Dict[int, float], coeff=1.0) -> Dict[int, float]:\n",
        "  return {k:(a.get(k,0) + coeff * b.get(k,0)) for k in (a.keys() | b.keys()) if abs(a.get(k,0) + coeff * b.get(k,0)) > epsilon}\n",
        "\n",
        "def minus(a: Dict[int,float], b: Dict[int,float]):\n",
        "  return {k:a.get(k,0)*b.get(k,0) for k in a.keys()|b.keys()}\n",
        "\n",
        "def np_sum(v):\n",
        "  return functools.reduce(lambda a,b : a+b, v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "4595d1c9-f46f-4083-b801-896ef6ffe15c",
          "showTitle": false,
          "title": ""
        },
        "id": "zrHGMqaGaHI8"
      },
      "source": [
        "### Convert to vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "2bdf9940-ef71-4179-b028-6f486aded04e",
          "showTitle": false,
          "title": ""
        },
        "id": "gLM0jaeDaHI9"
      },
      "outputs": [],
      "source": [
        "def row_to_vector(\n",
        "    row: Row, dimension: int, encoder: Dict[str, Dict[str, int]]\n",
        ") -> Tuple[Dict[int,float], int]:\n",
        "    x = {}\n",
        "    x[dimension-1] = 1 # for intercept\n",
        "    y = row['label']\n",
        "    for feat in encoder.keys():\n",
        "        value = row[feat]\n",
        "        index = encoder[feat].get(value, None)\n",
        "        if index != None:\n",
        "            x[index] = 1\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "a043f605-1d1a-486f-b1c0-6dcbc5f1a649",
          "showTitle": false,
          "title": ""
        },
        "id": "R7jweKmSaHI9"
      },
      "outputs": [],
      "source": [
        "def convert_to_vectors(\n",
        "    df: DataFrame, dimension: int, encoder: Dict[str, Dict[str, int]]\n",
        ") -> RDD:\n",
        "    features = encoder.keys()\n",
        "    return df\\\n",
        "        .select('label', *features).rdd\\\n",
        "        .map(lambda row: row_to_vector(row, dimension, encoder))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "6037b886-4ec4-4614-879a-dc31f7c1208b",
          "showTitle": false,
          "title": ""
        },
        "id": "doX9VC3vaHI-"
      },
      "outputs": [],
      "source": [
        "convert_to_vectors(full_df, dimension, one_hot_encoder).first()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "b2b44c95-c7f7-41c7-909b-c92b6cdcc1ec",
          "showTitle": false,
          "title": ""
        },
        "id": "lo4wTSolaHI-"
      },
      "source": [
        "## Compute loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "eeac88d0-f667-4570-ac82-4fb37e180789",
          "showTitle": false,
          "title": ""
        },
        "id": "CtgR1reoaHI_"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x: float) -> float:\n",
        "    return 1 / (1 + math.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "88263a00-34eb-4e88-8333-79c132814c28",
          "showTitle": false,
          "title": ""
        },
        "id": "aQO4emSmaHI_"
      },
      "outputs": [],
      "source": [
        "X = [-10+0.01*i for i in range(2000)]\n",
        "plot.plot(X, [sigmoid(x) for x in X])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "369a3c4e-8d75-48d4-adec-d2fe432c751d",
          "showTitle": false,
          "title": ""
        },
        "id": "EWJ09uvJaHJA"
      },
      "outputs": [],
      "source": [
        "def point_predict(x: Dict[int,float], model: Dict[int,float]) -> float:\n",
        "  return sigmoid(dot_product(x, model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "a2bfacbf-6614-445b-963d-428808c409aa",
          "showTitle": false,
          "title": ""
        },
        "id": "Eo0TY0ajaHJB"
      },
      "outputs": [],
      "source": [
        "def point_loss(prediction: float, y: int) -> float:\n",
        "  return - y * math.log(prediction) - (1-y) * math.log(1-prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "a978dc5f-d5b6-48c8-9760-37c27ac23237",
          "showTitle": false,
          "title": ""
        },
        "id": "Siv5B6IQaHJB"
      },
      "outputs": [],
      "source": [
        "def compute_loss(vec_label_rdd: RDD, model: Dict[int,float], num_examples: int) -> float:\n",
        "    sum_loss = (vec_label_rdd\n",
        "        .map(lambda vec_lab: point_loss(point_predict(vec_lab[0], model), vec_lab[1]))\n",
        "        .reduce(lambda u, v: u+v)\n",
        "               )\n",
        "    return sum_loss / num_examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "0f3cfd7c-1252-45e7-aabe-af97ca030d91",
          "showTitle": false,
          "title": ""
        },
        "id": "ujuFjvpVaHJC"
      },
      "source": [
        "## Compute gradient of the loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "47d5d024-160f-4887-97c8-2f17089c0197",
          "showTitle": false,
          "title": ""
        },
        "id": "s01rIGB4aHJC"
      },
      "outputs": [],
      "source": [
        "def point_gradient(x: Dict[int,float], y: int, model: Dict[int,float]) -> float:\n",
        "    dp = dot_product(x, model)\n",
        "    p = sigmoid(dp)\n",
        "    return product(x, p-y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "901ac2e6-e0d2-4a59-83d0-37cecf85a0e7",
          "showTitle": false,
          "title": ""
        },
        "id": "oLH77Nw5aHJD"
      },
      "outputs": [],
      "source": [
        "def compute_gradient(vec_label_rdd: RDD, model: Dict[int,float], num_examples: int) -> Dict[int,float]:\n",
        "    sum_gradient = (vec_label_rdd\n",
        "        .map(lambda vec_lab: point_gradient(vec_lab[0], vec_lab[1], model))\n",
        "        .reduce(lambda u, v: sum(u,v))\n",
        "                   )\n",
        "    return product(sum_gradient, 1.0/num_examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "03e7c0f9-480d-4c51-b9a8-1bfc0b6387da",
          "showTitle": false,
          "title": ""
        },
        "id": "iCXWyotMaHJD"
      },
      "source": [
        "## Check gradient with finite differences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "a407732d-9359-4c83-b9c8-83860298e7bb",
          "showTitle": false,
          "title": ""
        },
        "id": "bUM6nXhiaHJE"
      },
      "outputs": [],
      "source": [
        "def point_gradient_fd(x, y, model, h=0.001):\n",
        "    dimension = len(x)\n",
        "    gradient = {}\n",
        "    for i in range(0, dimension):\n",
        "        delta = {}\n",
        "        delta[i] = h\n",
        "        \n",
        "        loss_up = point_loss(point_predict(x, sum(model, delta)), y)\n",
        "        loss_down = point_loss(point_predict(x, sum(model, delta)), y)\n",
        "        \n",
        "        this_loss = (loss_up - loss_down) / (2*h)\n",
        "        if abs(this_loss) > epsilon:\n",
        "          gradient[i] = this_loss\n",
        "    return gradient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "3994ceb7-6e14-4023-a86e-d6a10d852368",
          "showTitle": false,
          "title": ""
        },
        "id": "5kGSb-X5aHJF"
      },
      "outputs": [],
      "source": [
        "from random import uniform\n",
        "def np_random_uniform(start, end, size):\n",
        "  return {i:uniform(start,end) for i in range(size)}\n",
        "\n",
        "model = np_random_uniform(-1.0, 1.0, dimension)\n",
        "x = np_random_uniform(-1.0, 1.0, dimension)\n",
        "y = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "fe103a36-54dc-4e7f-aacc-38cd3f4af248",
          "showTitle": false,
          "title": ""
        },
        "id": "0AYdD49WaHJG"
      },
      "outputs": [],
      "source": [
        "def np_abs(v):\n",
        "  return {i:abs(v[i]) for i in range(len(v))}\n",
        "np_sum(np_abs(minus(point_gradient_fd(x, y, model), point_gradient(x, y, model))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "07fb9c2a-2ff9-4c72-a212-a08312320915",
          "showTitle": false,
          "title": ""
        },
        "id": "ost_VVczaHJG"
      },
      "source": [
        "## Distributed Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "2ba14188-44f2-463d-a262-3e4e3bb27230",
          "showTitle": false,
          "title": ""
        },
        "id": "x4FlCRz9aHJH"
      },
      "outputs": [],
      "source": [
        "def logit(x: float) -> float:\n",
        "    return math.log( x / (1-x) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "983e123c-d809-453a-8f75-4125e99eeb9e",
          "showTitle": false,
          "title": ""
        },
        "id": "pId_p7fSaHJI"
      },
      "outputs": [],
      "source": [
        "np_sum(np_abs([x - logit(sigmoid(x)) for x in X]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "3f584319-a975-45b3-80dc-119602c33a1c",
          "showTitle": false,
          "title": ""
        },
        "id": "xs6vEsUYaHJI"
      },
      "outputs": [],
      "source": [
        "def smart_init(dimension: int, avg_label: float) -> Dict[int,float]:\n",
        "    init_model = {}\n",
        "    init_model[dimension-1] = logit(avg_label)\n",
        "    return init_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "a6c8fbf2-9d94-40d2-948c-11b5e56951e7",
          "showTitle": false,
          "title": ""
        },
        "id": "PbgqJ5MvaHJJ"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    training_set: DataFrame,\n",
        "    dimension: int,\n",
        "    encoder: Dict[str, Dict[str, int]],\n",
        "    nb_iter: int,\n",
        "    lr: float\n",
        ") -> Tuple[Dict[int,float], float]:\n",
        "    num_examples, avg_label = training_set.agg(\n",
        "        sf.count('*').alias('num_examples'),\n",
        "        sf.mean('label').alias('avg_label')\n",
        "    ).collect()[0]\n",
        "    print(f'Num examples: {num_examples}, average label: {avg_label}')\n",
        "    model = smart_init(dimension, avg_label)\n",
        "    vector_label_rdd = convert_to_vectors(training_set, dimension, encoder).persist()\n",
        "    for it in range(0, nb_iter):\n",
        "        loss = compute_loss(vector_label_rdd, model, num_examples)\n",
        "        print(f'Loss at step {it}: {loss}')\n",
        "        gradient = compute_gradient(vector_label_rdd, model, num_examples)\n",
        "        model = sum(model, gradient, -lr)\n",
        "    final_loss = compute_loss(vector_label_rdd, model, num_examples)\n",
        "    print(f'Loss at step {nb_iter}: {final_loss}')\n",
        "    return model, final_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "5a6e0895-ca4a-4fc4-b0be-691e2bef00f8",
          "showTitle": false,
          "title": ""
        },
        "id": "ZT-wS8pHaHJK"
      },
      "outputs": [],
      "source": [
        "model, loss = train(full_df, dimension, one_hot_encoder, 10, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "36e71a99-625d-41a9-912a-fa906120f4af",
          "showTitle": false,
          "title": ""
        },
        "id": "w-YvyqxQaHJK"
      },
      "outputs": [],
      "source": [
        "print(f'intercept -> {model[dimension-1]}')\n",
        "print(f'nb coefficients -> {len(model.keys())}')\n",
        "for dim in one_hot_encoder.keys():\n",
        "    for mod, index in one_hot_encoder[dim].items():\n",
        "      print(f'{dim}={mod} -> {model.get(index,0)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "bbd317e1-2e1a-4662-8aa3-bae3b9e97444",
          "showTitle": false,
          "title": ""
        },
        "id": "txs06n2XaHJL"
      },
      "outputs": [],
      "source": [
        "ss.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "c158fa4b-700d-4bd4-a248-553e2843b771",
          "showTitle": false,
          "title": ""
        },
        "id": "nNxWf-xDaHJM"
      },
      "source": [
        "### More questions\n",
        "\n",
        "* use sparse vectors\n",
        "* add feature hashing\n",
        "* merge loss and gradient computation in one function\n",
        "* use lbfgs from scipy"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 2
      },
      "notebookName": "distributed-gradient-descent-solution-sparse",
      "notebookOrigID": 1068043367735202,
      "widgets": {}
    },
    "colab": {
      "name": "td3-distributed-gradient-descent-solution-sparse.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
